{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eslywadan/bert/blob/master/%E3%80%8Cmt5_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SSF6fExEAmYy"
      },
      "outputs": [],
      "source": [
        "# change runtime to use gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-KKJD5ylw9H",
        "outputId": "53c4e208-e968-4c35-85ea-0fb657408fce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 53 kB 2.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 377 kB 53.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.3 MB/s \n",
            "\u001b[?25h  Building wheel for bert4keras (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.2+zzzcolab20220719082949 requires keras<2.9,>=2.8.0rc0, but you have keras 2.3.1 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 14.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 135 kB 11.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 96 kB 2.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 57 kB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 169 kB 49.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 14.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 60.5 MB/s \n",
            "\u001b[?25h  Building wheel for gsutil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gcs-oauth2-boto-plugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for retry-decorator (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyu2f (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-api-core 1.31.6 requires google-auth<2.0dev,>=1.25.0, but you have google-auth 2.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 377.1 MB 9.0 kB/s \n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 11.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 488 kB 59.8 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.2+zzzcolab20220719082949 requires keras<2.9,>=2.8.0rc0, but you have keras 2.3.1 which is incompatible.\n",
            "tensorflow 2.8.2+zzzcolab20220719082949 requires tensorboard<2.9,>=2.8, but you have tensorboard 1.14.0 which is incompatible.\n",
            "tensorflow 2.8.2+zzzcolab20220719082949 requires tensorflow-estimator<2.9,>=2.8, but you have tensorflow-estimator 1.14.0 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 41.2 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install bert4keras --quiet\n",
        "!pip install gsutil --quiet\n",
        "!pip install tensorflow-gpu==1.14 --quiet\n",
        "!pip install rouge --quiet\n",
        "!pip install sentencepiece --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tgqdbxPQmBKv"
      },
      "outputs": [],
      "source": [
        "import subprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGode0o-mrB7",
        "outputId": "455c80f6-2107-4f0c-c463-a20b38928894"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletedProcess(args=['gsutil', 'cp', '-r', 'gs://t5-data/pretrained_models/mt5/small', '.'], returncode=0)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "subprocess.run([\"gsutil\", \"cp\",  \"-r\",  \"gs://t5-data/pretrained_models/mt5/small\",  \".\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujJvNWF-npv_",
        "outputId": "42926606-11d5-4d25-e61a-ed4da04734b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CompletedProcess(args=['gsutil', 'cp', '-r', 'gs://t5-data/vocabs/mc4.250000.100extra/sentencepiece.model', '.'], returncode=0)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "subprocess.run([\"gsutil\",  \"cp\", \"-r\", \"gs://t5-data/vocabs/mc4.250000.100extra/sentencepiece.model\", \".\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKbahyIkn_tk",
        "outputId": "84ca0422-241d-4c70-8682-9104fd259024"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-10-03 07:52:29--  https://github.com/bojone/t5_in_bert4keras/blob/main/tokenizer/sentencepiece_cn.model\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘sentencepiece_cn.model.1’\n",
            "\n",
            "\rsentencepiece_cn.mo     [<=>                 ]       0  --.-KB/s               \rsentencepiece_cn.mo     [ <=>                ] 139.93K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2022-10-03 07:52:29 (11.6 MB/s) - ‘sentencepiece_cn.model.1’ saved [143293]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# !wget https://github.com/bojone/t5_in_bert4keras/blob/main/tokenizer/sentencepiece_cn.model\n",
        "# !wget https://github.com/bojone/t5_in_bert4keras/blob/main/tokenizer/sentencepiece_cn_keep_tokens.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sF7tpcEq9mJ",
        "outputId": "78d0995c-01ab-4a06-a046-13e2a9441731"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "Using TensorFlow backend.\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from bert4keras.backend import keras, K\n",
        "from bert4keras.layers import Loss\n",
        "from bert4keras.models import build_transformer_model\n",
        "from bert4keras.tokenizers import SpTokenizer\n",
        "from bert4keras.optimizers import Adam\n",
        "from bert4keras.snippets import sequence_padding, open\n",
        "from bert4keras.snippets import DataGenerator, AutoRegressiveDecoder\n",
        "from keras.models import Model\n",
        "from rouge import Rouge  # pip install rouge\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Hs1L2m6p-fA"
      },
      "outputs": [],
      "source": [
        "def load_data(filename):\n",
        "    D = []\n",
        "    with open(filename, encoding='utf-8') as f:\n",
        "        for i, l in enumerate(f):\n",
        "            if i == 0:\n",
        "                continue\n",
        "            title, abstract, keywords, discipline, category = l.strip().split('\\t')\n",
        "            D.append((title, abstract))\n",
        "    return D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpAiBWzWvHFV"
      },
      "outputs": [],
      "source": [
        "class data_generator(DataGenerator):\n",
        "    \"\"\"数据生成器\n",
        "    \"\"\"\n",
        "    def __iter__(self, random=False):\n",
        "        batch_c_token_ids, batch_t_token_ids = [], []\n",
        "        for is_end, (title, content) in self.sample(random):\n",
        "            c_token_ids, _ = tokenizer.encode(content, maxlen=max_c_len)\n",
        "            t_token_ids, _ = tokenizer.encode(title, maxlen=max_t_len)\n",
        "            batch_c_token_ids.append(c_token_ids)\n",
        "            batch_t_token_ids.append([0] + t_token_ids)\n",
        "            if len(batch_c_token_ids) == self.batch_size or is_end:\n",
        "                batch_c_token_ids = sequence_padding(batch_c_token_ids)\n",
        "                batch_t_token_ids = sequence_padding(batch_t_token_ids)\n",
        "                yield [batch_c_token_ids, batch_t_token_ids], None\n",
        "                batch_c_token_ids, batch_t_token_ids = [], []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lUHOqX32HuU"
      },
      "outputs": [],
      "source": [
        "class CrossEntropy(Loss):\n",
        "    \"\"\"交叉熵作为loss，并mask掉输入部分\n",
        "    \"\"\"\n",
        "    def compute_loss(self, inputs, mask=None):\n",
        "        y_true, y_pred = inputs\n",
        "        y_true = y_true[:, 1:]  # 目标token_ids\n",
        "        y_mask = K.cast(mask[1], K.floatx())[:, :-1]  # 解码器自带mask\n",
        "        y_pred = y_pred[:, :-1]  # 预测序列，错开一位\n",
        "        loss = K.sparse_categorical_crossentropy(y_true, y_pred)\n",
        "        loss = K.sum(loss * y_mask) / K.sum(y_mask)\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8DPJrM49Qeh"
      },
      "outputs": [],
      "source": [
        "config_path = './mt5_small_config.json'\n",
        "checkpoint_path = './small/model.ckpt-1000000'\n",
        "spm_path = './sentencepiece.model'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I--kOzNV9FmL"
      },
      "outputs": [],
      "source": [
        "mt5_small_cfg = {\n",
        "  \"hidden_dropout_prob\": 0.1,\n",
        "  \"hidden_size\": 512,\n",
        "  \"initializer_range\": 0.02,\n",
        "  \"intermediate_size\": 1024,\n",
        "  \"num_attention_heads\": 6,\n",
        "  \"attention_head_size\": 64,\n",
        "  \"num_hidden_layers\": 8,\n",
        "  \"vocab_size\": 250112,\n",
        "  \"hidden_act\": [\"gelu\", \"linear\"]\n",
        "}\n",
        "with open(config_path, 'w') as f:\n",
        "    json.dump(mt5_small_cfg, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SCnT12B9cva",
        "outputId": "7e30cdef-be61-453e-b875-6f73a0e1ca71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nraKmhKQ9zH0"
      },
      "outputs": [],
      "source": [
        "# https://github.com/ydli-ai/CSL\n",
        "# https://drive.google.com/drive/u/3/folders/1f1D6kk4dmfJv5iFQ2jLkxAykLiou6xcz\n",
        "# add to drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKZY5MML8CZ9",
        "outputId": "85e26981-66ce-4424-d911-18be988b8eae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('分布式系统中的检查点算法',\n",
              " '检查点能够保存和恢复程序的运行状态.它在进程迁移、容错、卷回调试等领域都有重要的应用.本文对分布式系统中的检查点算法进行了详细的分类评述.检查点算法可分为单进程和分布式程序检查点算法,分布式程序检查点算法又可分为异步检查点算法和一致检查点算法.同时本文系统介绍了改进检查点算法性能的典型方法.这些改进算法主要采用两个策略来减少算法的开销与延迟:一是减少检查点文件中需要存储的信息量,如增量算法等;二是提高检查点操作与目标程序运行的并行性,如主存算法等.最后,文章讨论了目前检查点算法的局限性和进一步的工作.')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data = load_data('/content/drive/MyDrive/Colab Notebooks/csl_40k.tsv')\n",
        "train_data[0][0], train_data[0][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0Q8wz5A799-"
      },
      "outputs": [],
      "source": [
        "tokenizer = SpTokenizer(spm_path, token_start=None, token_end='&lt;/s&gt;')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtJvfBpy2LNQ",
        "outputId": "a28d8816-7be7-488f-af04-2aca7a7843ec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3170: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ]
        }
      ],
      "source": [
        "t5 = build_transformer_model(\n",
        "    config_path=config_path,\n",
        "    checkpoint_path=checkpoint_path,\n",
        "    model='mt5.1.1',\n",
        "    return_keras_model=False,\n",
        "    name='T5',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRIsJGa_2OVo",
        "outputId": "740393df-c6f9-4b23-c4a4-5e8812b0d293"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Decoder-Input-Token (InputLayer (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Input-Token (InputLayer (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Token (Embedding)     (None, None, 512)    128057344   Encoder-Input-Token[0][0]        \n",
            "                                                                 Decoder-Input-Token[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Embedding-Dropout (Drop (None, None, 512)    0           Embedding-Token[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-0-MultiHead (None, None, 512)    512         Encoder-Embedding-Dropout[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Embedding-Relative-Posi (None, None, 6)      192         Encoder-Embedding-Dropout[0][0]  \n",
            "                                                                 Encoder-Embedding-Dropout[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-0-MultiHead (None, None, 512)    786432      Encoder-Transformer-0-MultiHeadSe\n",
            "                                                                 Encoder-Transformer-0-MultiHeadSe\n",
            "                                                                 Encoder-Transformer-0-MultiHeadSe\n",
            "                                                                 Encoder-Embedding-Relative-Positi\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-0-MultiHead (None, None, 512)    0           Encoder-Transformer-0-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-0-MultiHead (None, None, 512)    0           Encoder-Embedding-Dropout[0][0]  \n",
            "                                                                 Encoder-Transformer-0-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-0-FeedForwa (None, None, 512)    512         Encoder-Transformer-0-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-0-FeedForwa (None, None, 512)    1572864     Encoder-Transformer-0-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-0-FeedForwa (None, None, 512)    0           Encoder-Transformer-0-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-0-FeedForwa (None, None, 512)    0           Encoder-Transformer-0-MultiHeadSe\n",
            "                                                                 Encoder-Transformer-0-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-1-MultiHead (None, None, 512)    512         Encoder-Transformer-0-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-1-MultiHead (None, None, 512)    786432      Encoder-Transformer-1-MultiHeadSe\n",
            "                                                                 Encoder-Transformer-1-MultiHeadSe\n",
            "                                                                 Encoder-Transformer-1-MultiHeadSe\n",
            "                                                                 Encoder-Embedding-Relative-Positi\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-1-MultiHead (None, None, 512)    0           Encoder-Transformer-1-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-1-MultiHead (None, None, 512)    0           Encoder-Transformer-0-FeedForward\n",
            "                                                                 Encoder-Transformer-1-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-1-FeedForwa (None, None, 512)    512         Encoder-Transformer-1-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-1-FeedForwa (None, None, 512)    1572864     Encoder-Transformer-1-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-1-FeedForwa (None, None, 512)    0           Encoder-Transformer-1-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-1-FeedForwa (None, None, 512)    0           Encoder-Transformer-1-MultiHeadSe\n",
            "                                                                 Encoder-Transformer-1-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-2-MultiHead (None, None, 512)    512         Encoder-Transformer-1-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-2-MultiHead (None, None, 512)    786432      Encoder-Transformer-2-MultiHeadSe\n",
            "                                                                 Encoder-Transformer-2-MultiHeadSe\n",
            "                                                                 Encoder-Transformer-2-MultiHeadSe\n",
            "                                                                 Encoder-Embedding-Relative-Positi\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-2-MultiHead (None, None, 512)    0           Encoder-Transformer-2-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-2-MultiHead (None, None, 512)    0           Encoder-Transformer-1-FeedForward\n",
            "                                                                 Encoder-Transformer-2-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-2-FeedForwa (None, None, 512)    512         Encoder-Transformer-2-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-2-FeedForwa (None, None, 512)    1572864     Encoder-Transformer-2-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-2-FeedForwa (None, None, 512)    0           Encoder-Transformer-2-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-2-FeedForwa (None, None, 512)    0           Encoder-Transformer-2-MultiHeadSe\n",
            "                                                                 Encoder-Transformer-2-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-3-MultiHead (None, None, 512)    512         Encoder-Transformer-2-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-3-MultiHead (None, None, 512)    786432      Encoder-Transformer-3-MultiHeadSe\n",
            "                                                                 Encoder-Transformer-3-MultiHeadSe\n",
            "                                                                 Encoder-Transformer-3-MultiHeadSe\n",
            "                                                                 Encoder-Embedding-Relative-Positi\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-3-MultiHead (None, None, 512)    0           Encoder-Transformer-3-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-3-MultiHead (None, None, 512)    0           Encoder-Transformer-2-FeedForward\n",
            "                                                                 Encoder-Transformer-3-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-3-FeedForwa (None, None, 512)    512         Encoder-Transformer-3-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-3-FeedForwa (None, None, 512)    1572864     Encoder-Transformer-3-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-3-FeedForwa (None, None, 512)    0           Encoder-Transformer-3-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-3-FeedForwa (None, None, 512)    0           Encoder-Transformer-3-MultiHeadSe\n",
            "                                                                 Encoder-Transformer-3-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-4-MultiHead (None, None, 512)    512         Encoder-Transformer-3-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-4-MultiHead (None, None, 512)    786432      Encoder-Transformer-4-MultiHeadSe\n",
            "                                                                 Encoder-Transformer-4-MultiHeadSe\n",
            "                                                                 Encoder-Transformer-4-MultiHeadSe\n",
            "                                                                 Encoder-Embedding-Relative-Positi\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-4-MultiHead (None, None, 512)    0           Encoder-Transformer-4-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-4-MultiHead (None, None, 512)    0           Encoder-Transformer-3-FeedForward\n",
            "                                                                 Encoder-Transformer-4-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-4-FeedForwa (None, None, 512)    512         Encoder-Transformer-4-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-4-FeedForwa (None, None, 512)    1572864     Encoder-Transformer-4-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-4-FeedForwa (None, None, 512)    0           Encoder-Transformer-4-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-4-FeedForwa (None, None, 512)    0           Encoder-Transformer-4-MultiHeadSe\n",
            "                                                                 Encoder-Transformer-4-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-5-MultiHead (None, None, 512)    512         Encoder-Transformer-4-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-5-MultiHead (None, None, 512)    786432      Encoder-Transformer-5-MultiHeadSe\n",
            "                                                                 Encoder-Transformer-5-MultiHeadSe\n",
            "                                                                 Encoder-Transformer-5-MultiHeadSe\n",
            "                                                                 Encoder-Embedding-Relative-Positi\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-5-MultiHead (None, None, 512)    0           Encoder-Transformer-5-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-5-MultiHead (None, None, 512)    0           Encoder-Transformer-4-FeedForward\n",
            "                                                                 Encoder-Transformer-5-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-5-FeedForwa (None, None, 512)    512         Encoder-Transformer-5-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-5-FeedForwa (None, None, 512)    1572864     Encoder-Transformer-5-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-5-FeedForwa (None, None, 512)    0           Encoder-Transformer-5-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-5-FeedForwa (None, None, 512)    0           Encoder-Transformer-5-MultiHeadSe\n",
            "                                                                 Encoder-Transformer-5-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-6-MultiHead (None, None, 512)    512         Encoder-Transformer-5-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-6-MultiHead (None, None, 512)    786432      Encoder-Transformer-6-MultiHeadSe\n",
            "                                                                 Encoder-Transformer-6-MultiHeadSe\n",
            "                                                                 Encoder-Transformer-6-MultiHeadSe\n",
            "                                                                 Encoder-Embedding-Relative-Positi\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-6-MultiHead (None, None, 512)    0           Encoder-Transformer-6-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-6-MultiHead (None, None, 512)    0           Encoder-Transformer-5-FeedForward\n",
            "                                                                 Encoder-Transformer-6-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-6-FeedForwa (None, None, 512)    512         Encoder-Transformer-6-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-6-FeedForwa (None, None, 512)    1572864     Encoder-Transformer-6-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-6-FeedForwa (None, None, 512)    0           Encoder-Transformer-6-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-6-FeedForwa (None, None, 512)    0           Encoder-Transformer-6-MultiHeadSe\n",
            "                                                                 Encoder-Transformer-6-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-7-MultiHead (None, None, 512)    512         Encoder-Transformer-6-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-7-MultiHead (None, None, 512)    786432      Encoder-Transformer-7-MultiHeadSe\n",
            "                                                                 Encoder-Transformer-7-MultiHeadSe\n",
            "                                                                 Encoder-Transformer-7-MultiHeadSe\n",
            "                                                                 Encoder-Embedding-Relative-Positi\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-7-MultiHead (None, None, 512)    0           Encoder-Transformer-7-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-7-MultiHead (None, None, 512)    0           Encoder-Transformer-6-FeedForward\n",
            "                                                                 Encoder-Transformer-7-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-7-FeedForwa (None, None, 512)    512         Encoder-Transformer-7-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Embedding-Dropout (Drop (None, None, 512)    0           Embedding-Token[2][0]            \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-7-FeedForwa (None, None, 512)    1572864     Encoder-Transformer-7-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-0-MultiHead (None, None, 512)    512         Decoder-Embedding-Dropout[1][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Attention-LM-Mask (Lambda)      (None, None)         0           Decoder-Input-Token[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Embedding-Relative-Posi (None, None, 6)      192         Decoder-Embedding-Dropout[1][0]  \n",
            "                                                                 Decoder-Embedding-Dropout[1][0]  \n",
            "                                                                 Decoder-Embedding-Dropout[1][0]  \n",
            "                                                                 Encoder-Output-Dropout[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-7-FeedForwa (None, None, 512)    0           Encoder-Transformer-7-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-0-MultiHead (None, None, 512)    786432      Decoder-Transformer-0-MultiHeadSe\n",
            "                                                                 Decoder-Transformer-0-MultiHeadSe\n",
            "                                                                 Decoder-Transformer-0-MultiHeadSe\n",
            "                                                                 Attention-LM-Mask[0][0]          \n",
            "                                                                 Decoder-Embedding-Relative-Positi\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Transformer-7-FeedForwa (None, None, 512)    0           Encoder-Transformer-7-MultiHeadSe\n",
            "                                                                 Encoder-Transformer-7-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-0-MultiHead (None, None, 512)    0           Decoder-Transformer-0-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Output-Norm (LayerNorma (None, None, 512)    512         Encoder-Transformer-7-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-0-MultiHead (None, None, 512)    0           Decoder-Embedding-Dropout[1][0]  \n",
            "                                                                 Decoder-Transformer-0-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Output-Dropout (Dropout (None, None, 512)    0           Encoder-Output-Norm[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-0-MultiHead (None, None, 512)    512         Decoder-Transformer-0-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-0-MultiHead (None, None, 512)    786432      Decoder-Transformer-0-MultiHeadCr\n",
            "                                                                 Encoder-Output-Dropout[0][0]     \n",
            "                                                                 Encoder-Output-Dropout[0][0]     \n",
            "                                                                 Decoder-Embedding-Relative-Positi\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-0-MultiHead (None, None, 512)    0           Decoder-Transformer-0-MultiHeadCr\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-0-MultiHead (None, None, 512)    0           Decoder-Transformer-0-MultiHeadSe\n",
            "                                                                 Decoder-Transformer-0-MultiHeadCr\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-0-FeedForwa (None, None, 512)    512         Decoder-Transformer-0-MultiHeadCr\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-0-FeedForwa (None, None, 512)    1572864     Decoder-Transformer-0-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-0-FeedForwa (None, None, 512)    0           Decoder-Transformer-0-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-0-FeedForwa (None, None, 512)    0           Decoder-Transformer-0-MultiHeadCr\n",
            "                                                                 Decoder-Transformer-0-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-1-MultiHead (None, None, 512)    512         Decoder-Transformer-0-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-1-MultiHead (None, None, 512)    786432      Decoder-Transformer-1-MultiHeadSe\n",
            "                                                                 Decoder-Transformer-1-MultiHeadSe\n",
            "                                                                 Decoder-Transformer-1-MultiHeadSe\n",
            "                                                                 Attention-LM-Mask[0][0]          \n",
            "                                                                 Decoder-Embedding-Relative-Positi\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-1-MultiHead (None, None, 512)    0           Decoder-Transformer-1-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-1-MultiHead (None, None, 512)    0           Decoder-Transformer-0-FeedForward\n",
            "                                                                 Decoder-Transformer-1-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-1-MultiHead (None, None, 512)    512         Decoder-Transformer-1-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-1-MultiHead (None, None, 512)    786432      Decoder-Transformer-1-MultiHeadCr\n",
            "                                                                 Encoder-Output-Dropout[0][0]     \n",
            "                                                                 Encoder-Output-Dropout[0][0]     \n",
            "                                                                 Decoder-Embedding-Relative-Positi\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-1-MultiHead (None, None, 512)    0           Decoder-Transformer-1-MultiHeadCr\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-1-MultiHead (None, None, 512)    0           Decoder-Transformer-1-MultiHeadSe\n",
            "                                                                 Decoder-Transformer-1-MultiHeadCr\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-1-FeedForwa (None, None, 512)    512         Decoder-Transformer-1-MultiHeadCr\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-1-FeedForwa (None, None, 512)    1572864     Decoder-Transformer-1-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-1-FeedForwa (None, None, 512)    0           Decoder-Transformer-1-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-1-FeedForwa (None, None, 512)    0           Decoder-Transformer-1-MultiHeadCr\n",
            "                                                                 Decoder-Transformer-1-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-2-MultiHead (None, None, 512)    512         Decoder-Transformer-1-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-2-MultiHead (None, None, 512)    786432      Decoder-Transformer-2-MultiHeadSe\n",
            "                                                                 Decoder-Transformer-2-MultiHeadSe\n",
            "                                                                 Decoder-Transformer-2-MultiHeadSe\n",
            "                                                                 Attention-LM-Mask[0][0]          \n",
            "                                                                 Decoder-Embedding-Relative-Positi\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-2-MultiHead (None, None, 512)    0           Decoder-Transformer-2-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-2-MultiHead (None, None, 512)    0           Decoder-Transformer-1-FeedForward\n",
            "                                                                 Decoder-Transformer-2-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-2-MultiHead (None, None, 512)    512         Decoder-Transformer-2-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-2-MultiHead (None, None, 512)    786432      Decoder-Transformer-2-MultiHeadCr\n",
            "                                                                 Encoder-Output-Dropout[0][0]     \n",
            "                                                                 Encoder-Output-Dropout[0][0]     \n",
            "                                                                 Decoder-Embedding-Relative-Positi\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-2-MultiHead (None, None, 512)    0           Decoder-Transformer-2-MultiHeadCr\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-2-MultiHead (None, None, 512)    0           Decoder-Transformer-2-MultiHeadSe\n",
            "                                                                 Decoder-Transformer-2-MultiHeadCr\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-2-FeedForwa (None, None, 512)    512         Decoder-Transformer-2-MultiHeadCr\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-2-FeedForwa (None, None, 512)    1572864     Decoder-Transformer-2-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-2-FeedForwa (None, None, 512)    0           Decoder-Transformer-2-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-2-FeedForwa (None, None, 512)    0           Decoder-Transformer-2-MultiHeadCr\n",
            "                                                                 Decoder-Transformer-2-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-3-MultiHead (None, None, 512)    512         Decoder-Transformer-2-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-3-MultiHead (None, None, 512)    786432      Decoder-Transformer-3-MultiHeadSe\n",
            "                                                                 Decoder-Transformer-3-MultiHeadSe\n",
            "                                                                 Decoder-Transformer-3-MultiHeadSe\n",
            "                                                                 Attention-LM-Mask[0][0]          \n",
            "                                                                 Decoder-Embedding-Relative-Positi\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-3-MultiHead (None, None, 512)    0           Decoder-Transformer-3-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-3-MultiHead (None, None, 512)    0           Decoder-Transformer-2-FeedForward\n",
            "                                                                 Decoder-Transformer-3-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-3-MultiHead (None, None, 512)    512         Decoder-Transformer-3-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-3-MultiHead (None, None, 512)    786432      Decoder-Transformer-3-MultiHeadCr\n",
            "                                                                 Encoder-Output-Dropout[0][0]     \n",
            "                                                                 Encoder-Output-Dropout[0][0]     \n",
            "                                                                 Decoder-Embedding-Relative-Positi\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-3-MultiHead (None, None, 512)    0           Decoder-Transformer-3-MultiHeadCr\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-3-MultiHead (None, None, 512)    0           Decoder-Transformer-3-MultiHeadSe\n",
            "                                                                 Decoder-Transformer-3-MultiHeadCr\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-3-FeedForwa (None, None, 512)    512         Decoder-Transformer-3-MultiHeadCr\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-3-FeedForwa (None, None, 512)    1572864     Decoder-Transformer-3-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-3-FeedForwa (None, None, 512)    0           Decoder-Transformer-3-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-3-FeedForwa (None, None, 512)    0           Decoder-Transformer-3-MultiHeadCr\n",
            "                                                                 Decoder-Transformer-3-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-4-MultiHead (None, None, 512)    512         Decoder-Transformer-3-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-4-MultiHead (None, None, 512)    786432      Decoder-Transformer-4-MultiHeadSe\n",
            "                                                                 Decoder-Transformer-4-MultiHeadSe\n",
            "                                                                 Decoder-Transformer-4-MultiHeadSe\n",
            "                                                                 Attention-LM-Mask[0][0]          \n",
            "                                                                 Decoder-Embedding-Relative-Positi\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-4-MultiHead (None, None, 512)    0           Decoder-Transformer-4-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-4-MultiHead (None, None, 512)    0           Decoder-Transformer-3-FeedForward\n",
            "                                                                 Decoder-Transformer-4-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-4-MultiHead (None, None, 512)    512         Decoder-Transformer-4-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-4-MultiHead (None, None, 512)    786432      Decoder-Transformer-4-MultiHeadCr\n",
            "                                                                 Encoder-Output-Dropout[0][0]     \n",
            "                                                                 Encoder-Output-Dropout[0][0]     \n",
            "                                                                 Decoder-Embedding-Relative-Positi\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-4-MultiHead (None, None, 512)    0           Decoder-Transformer-4-MultiHeadCr\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-4-MultiHead (None, None, 512)    0           Decoder-Transformer-4-MultiHeadSe\n",
            "                                                                 Decoder-Transformer-4-MultiHeadCr\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-4-FeedForwa (None, None, 512)    512         Decoder-Transformer-4-MultiHeadCr\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-4-FeedForwa (None, None, 512)    1572864     Decoder-Transformer-4-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-4-FeedForwa (None, None, 512)    0           Decoder-Transformer-4-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-4-FeedForwa (None, None, 512)    0           Decoder-Transformer-4-MultiHeadCr\n",
            "                                                                 Decoder-Transformer-4-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-5-MultiHead (None, None, 512)    512         Decoder-Transformer-4-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-5-MultiHead (None, None, 512)    786432      Decoder-Transformer-5-MultiHeadSe\n",
            "                                                                 Decoder-Transformer-5-MultiHeadSe\n",
            "                                                                 Decoder-Transformer-5-MultiHeadSe\n",
            "                                                                 Attention-LM-Mask[0][0]          \n",
            "                                                                 Decoder-Embedding-Relative-Positi\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-5-MultiHead (None, None, 512)    0           Decoder-Transformer-5-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-5-MultiHead (None, None, 512)    0           Decoder-Transformer-4-FeedForward\n",
            "                                                                 Decoder-Transformer-5-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-5-MultiHead (None, None, 512)    512         Decoder-Transformer-5-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-5-MultiHead (None, None, 512)    786432      Decoder-Transformer-5-MultiHeadCr\n",
            "                                                                 Encoder-Output-Dropout[0][0]     \n",
            "                                                                 Encoder-Output-Dropout[0][0]     \n",
            "                                                                 Decoder-Embedding-Relative-Positi\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-5-MultiHead (None, None, 512)    0           Decoder-Transformer-5-MultiHeadCr\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-5-MultiHead (None, None, 512)    0           Decoder-Transformer-5-MultiHeadSe\n",
            "                                                                 Decoder-Transformer-5-MultiHeadCr\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-5-FeedForwa (None, None, 512)    512         Decoder-Transformer-5-MultiHeadCr\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-5-FeedForwa (None, None, 512)    1572864     Decoder-Transformer-5-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-5-FeedForwa (None, None, 512)    0           Decoder-Transformer-5-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-5-FeedForwa (None, None, 512)    0           Decoder-Transformer-5-MultiHeadCr\n",
            "                                                                 Decoder-Transformer-5-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-6-MultiHead (None, None, 512)    512         Decoder-Transformer-5-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-6-MultiHead (None, None, 512)    786432      Decoder-Transformer-6-MultiHeadSe\n",
            "                                                                 Decoder-Transformer-6-MultiHeadSe\n",
            "                                                                 Decoder-Transformer-6-MultiHeadSe\n",
            "                                                                 Attention-LM-Mask[0][0]          \n",
            "                                                                 Decoder-Embedding-Relative-Positi\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-6-MultiHead (None, None, 512)    0           Decoder-Transformer-6-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-6-MultiHead (None, None, 512)    0           Decoder-Transformer-5-FeedForward\n",
            "                                                                 Decoder-Transformer-6-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-6-MultiHead (None, None, 512)    512         Decoder-Transformer-6-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-6-MultiHead (None, None, 512)    786432      Decoder-Transformer-6-MultiHeadCr\n",
            "                                                                 Encoder-Output-Dropout[0][0]     \n",
            "                                                                 Encoder-Output-Dropout[0][0]     \n",
            "                                                                 Decoder-Embedding-Relative-Positi\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-6-MultiHead (None, None, 512)    0           Decoder-Transformer-6-MultiHeadCr\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-6-MultiHead (None, None, 512)    0           Decoder-Transformer-6-MultiHeadSe\n",
            "                                                                 Decoder-Transformer-6-MultiHeadCr\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-6-FeedForwa (None, None, 512)    512         Decoder-Transformer-6-MultiHeadCr\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-6-FeedForwa (None, None, 512)    1572864     Decoder-Transformer-6-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-6-FeedForwa (None, None, 512)    0           Decoder-Transformer-6-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-6-FeedForwa (None, None, 512)    0           Decoder-Transformer-6-MultiHeadCr\n",
            "                                                                 Decoder-Transformer-6-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-7-MultiHead (None, None, 512)    512         Decoder-Transformer-6-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-7-MultiHead (None, None, 512)    786432      Decoder-Transformer-7-MultiHeadSe\n",
            "                                                                 Decoder-Transformer-7-MultiHeadSe\n",
            "                                                                 Decoder-Transformer-7-MultiHeadSe\n",
            "                                                                 Attention-LM-Mask[0][0]          \n",
            "                                                                 Decoder-Embedding-Relative-Positi\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-7-MultiHead (None, None, 512)    0           Decoder-Transformer-7-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-7-MultiHead (None, None, 512)    0           Decoder-Transformer-6-FeedForward\n",
            "                                                                 Decoder-Transformer-7-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-7-MultiHead (None, None, 512)    512         Decoder-Transformer-7-MultiHeadSe\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-7-MultiHead (None, None, 512)    786432      Decoder-Transformer-7-MultiHeadCr\n",
            "                                                                 Encoder-Output-Dropout[0][0]     \n",
            "                                                                 Encoder-Output-Dropout[0][0]     \n",
            "                                                                 Decoder-Embedding-Relative-Positi\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-7-MultiHead (None, None, 512)    0           Decoder-Transformer-7-MultiHeadCr\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-7-MultiHead (None, None, 512)    0           Decoder-Transformer-7-MultiHeadSe\n",
            "                                                                 Decoder-Transformer-7-MultiHeadCr\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-7-FeedForwa (None, None, 512)    512         Decoder-Transformer-7-MultiHeadCr\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-7-FeedForwa (None, None, 512)    1572864     Decoder-Transformer-7-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-7-FeedForwa (None, None, 512)    0           Decoder-Transformer-7-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Transformer-7-FeedForwa (None, None, 512)    0           Decoder-Transformer-7-MultiHeadCr\n",
            "                                                                 Decoder-Transformer-7-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Output-Norm (LayerNorma (None, None, 512)    512         Decoder-Transformer-7-FeedForward\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Output-Dropout (Dropout (None, None, 512)    0           Decoder-Output-Norm[1][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Output-Scale (ScaleOffs (None, None, 512)    0           Decoder-Output-Dropout[1][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Output-LM (Dense)       (None, None, 250112) 128057344   Decoder-Output-Scale[1][0]       \n",
            "==================================================================================================\n",
            "Total params: 300,176,768\n",
            "Trainable params: 300,176,768\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_utils.py:819: UserWarning: Output cross_entropy_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to cross_entropy_1.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ]
        }
      ],
      "source": [
        "encoder = t5.encoder\n",
        "decoder = t5.decoder\n",
        "model = t5.model\n",
        "model.summary()\n",
        "\n",
        "output = CrossEntropy(1)([model.inputs[1], model.outputs[0]])\n",
        "\n",
        "model = Model(model.inputs, output)\n",
        "model.compile(optimizer=Adam(2e-4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lp_Ddd7P7Hf3"
      },
      "outputs": [],
      "source": [
        "max_c_len = 256\n",
        "max_t_len = 32\n",
        "batch_size = 16\n",
        "epochs = 40"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4jRQ3u863h2"
      },
      "outputs": [],
      "source": [
        "train_generator = data_generator(train_data, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAqX4IPz7RCj",
        "outputId": "ac1391c2-d176-47f6-d868-9125f870a1f0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py:90: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 128057344 elements. This may consume a large amount of memory.\n",
            "  num_elements)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "2500/2500 [==============================] - 1678s 671ms/step - loss: 4.0113\n",
            "Epoch 2/40\n",
            "2473/2500 [============================>.] - ETA: 18s - loss: 2.3497"
          ]
        }
      ],
      "source": [
        "model.fit(\n",
        "  train_generator.forfit(),\n",
        "  steps_per_epoch=len(train_generator),\n",
        "  epochs=epochs,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUWItcsG7cIe"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}